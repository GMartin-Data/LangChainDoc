{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence and Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [**this tutorial**](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/5/persistence-and-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Basic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate Search Tool\n",
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AgentState\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with **persistence**, we will use what's called a **checkpointer** into LangGraph.\n",
    "\n",
    "It basically **checkpoints the state between every node**.\n",
    "\n",
    "Here, we'll make use of a `SqliteSaver`, and use it \"in memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then really easy to incorporate it within our `Agent` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Agent\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):  # ðŸ‘ˆ REFERENCE TO CHECKPOINTER\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)  # ðŸ‘ˆ REFERENCE TO CHECKPOINTER\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**\n",
    ">\n",
    "> For data persistence, it can also be made use of other databases, or [**Redis**](https://redis.io/) for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  # ðŸ‘ˆ Change to -4o for POC\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now implement **threads**, in order to keep track of different conversations.\n",
    "\n",
    "They can simply be configured in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now call the graph, not with `invoke`, but with `stream`, passing:\n",
    "- the same dictionary,\n",
    "- `thread` as a second argument.\n",
    "\n",
    "We're then gonna get back a **stream** of events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is here to temporarily manage an issue with LangSmith, don't bother with understanding it for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LANGCHAIN_TRACING_V2=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1186, 'total_tokens': 1207}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-af070dca-58fc-42d1-9d5b-c2d081e72a86-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4'}], usage_metadata={'input_tokens': 1186, 'output_tokens': 21, 'total_tokens': 1207})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717751204, \\'localtime\\': \\'2024-06-07 2:06\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717750800, \\'last_updated\\': \\'2024-06-07 02:00\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 4.3, \\'wind_kph\\': 6.8, \\'wind_degree\\': 10, \\'wind_dir\\': \\'N\\', \\'pressure_mb\\': 1011.0, \\'pressure_in\\': 29.84, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 0, \\'feelslike_c\\': 10.7, \\'feelslike_f\\': 51.2, \\'windchill_c\\': 9.8, \\'windchill_f\\': 49.6, \\'heatindex_c\\': 11.4, \\'heatindex_f\\': 52.6, \\'dewpoint_c\\': 9.3, \\'dewpoint_f\\': 48.8, \\'vis_km\\': 14.0, \\'vis_miles\\': 8.0, \\'uv\\': 1.0, \\'gust_mph\\': 14.0, \\'gust_kph\\': 22.5}}\"}, {\\'url\\': \\'https://www.weather.gov/index.php/mtr/\\', \\'content\\': \\'Current Conditions showing NA; Customize Your Weather.gov. Enter Your City, ST or ZIP Code ... 2024 at 9:40:09 am PDT Watches, Warnings & Advisories. Zoom Out. Excessive Heat Warning. Gale Warning. Heat Advisory. Small Craft Advisory. ... National Weather Service San Francisco Bay Area, CA 21 Grace Hopper Ave, Stop 5 Monterey, CA 93943-5505\\'}]', name='tavily_search_results_json', tool_call_id='call_eqDDo3U0wuFrWTitkRpMCIw4')]\n",
      "[AIMessage(content='The current weather in San Francisco is clear with a temperature of 54.0Â°F (12.2Â°C). The wind is blowing at 4.3 mph from the north, and the humidity is at 93%.', response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1732, 'total_tokens': 1778}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-de9261f7-2481-4194-b1ac-0e9e5cebaf7b-0', usage_metadata={'input_tokens': 1732, 'output_tokens': 46, 'total_tokens': 1778})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back a stream of events:\n",
    "\n",
    "- first, we get an `AIMessage`, which is the first result from the language model.\n",
    "\n",
    "```python\n",
    "AIMessage(\n",
    "    content='',\n",
    "    additional_kwargs={\n",
    "        'tool_calls': [{\n",
    "            'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4',\n",
    "            'function': {\n",
    "                'arguments': '{\"query\":\"weather in San Francisco\"}',\n",
    "                'name': 'tavily_search_results_json'}, \n",
    "                'type': 'function'\n",
    "            }]\n",
    "        }, \n",
    "    response_metadata={\n",
    "        'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1186, 'total_tokens': 1207}, \n",
    "        'model_name': 'gpt-3.5-turbo', \n",
    "        'system_fingerprint': None, \n",
    "        'finish_reason': 'tool_calls', \n",
    "        'logprobs': None\n",
    "        }, \n",
    "    id='run-af070dca-58fc-42d1-9d5b-c2d081e72a86-0', \n",
    "    tool_calls=[{\n",
    "        'name': 'tavily_search_results_json', \n",
    "        'args': {'query': 'weather in San Francisco'}, \n",
    "        'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4'\n",
    "        }], \n",
    "    usage_metadata={'input_tokens': 1186, 'output_tokens': 21, 'total_tokens': 1207}\n",
    ")\n",
    "```\n",
    "- It tells us to call `tavily`, which is logged with this printing:\n",
    "\n",
    "```python\n",
    "Calling: {\n",
    "    'name': 'tavily_search_results_json',\n",
    "    'args': {'query': 'weather in San Francisco'},\n",
    "    'id': 'call_eqDDo3U0wuFrWTitkRpMCIw4'\n",
    "}\n",
    "```\n",
    "- Then, the action is performed, is logged with the printing of `Back to the model!`, and we get the following `ToolMessage` (I won't parse it now as it doesn't really improves readability), which is the result of calling `tavily` and, hence, the result of the search:\n",
    "\n",
    "```python\n",
    "ToolMessage(\n",
    "    content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717751204, \\'localtime\\': \\'2024-06-07 2:06\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717750800, \\'last_updated\\': \\'2024-06-07 02:00\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 4.3, \\'wind_kph\\': 6.8, \\'wind_degree\\': 10, \\'wind_dir\\': \\'N\\', \\'pressure_mb\\': 1011.0, \\'pressure_in\\': 29.84, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 0, \\'feelslike_c\\': 10.7, \\'feelslike_f\\': 51.2, \\'windchill_c\\': 9.8, \\'windchill_f\\': 49.6, \\'heatindex_c\\': 11.4, \\'heatindex_f\\': 52.6, \\'dewpoint_c\\': 9.3, \\'dewpoint_f\\': 48.8, \\'vis_km\\': 14.0, \\'vis_miles\\': 8.0, \\'uv\\': 1.0, \\'gust_mph\\': 14.0, \\'gust_kph\\': 22.5}}\"}, {\\'url\\': \\'https://www.weather.gov/index.php/mtr/\\', \\'content\\': \\'Current Conditions showing NA; Customize Your Weather.gov. Enter Your City, ST or ZIP Code ... 2024 at 9:40:09 am PDT Watches, Warnings & Advisories. Zoom Out. Excessive Heat Warning. Gale Warning. Heat Advisory. Small Craft Advisory. ... National Weather Service San Francisco Bay Area, CA 21 Grace Hopper Ave, Stop 5 Monterey, CA 93943-5505\\'}]', \n",
    "    name='tavily_search_results_json', \n",
    "    tool_call_id='call_eqDDo3U0wuFrWTitkRpMCIw4'\n",
    ")\n",
    "```\n",
    "- Finally, there's an `AIMessage`, which is the result of the LLM, answering our question:\n",
    "\n",
    "```python\n",
    "AIMessage(\n",
    "    content='The current weather in San Francisco is clear with a temperature of 54.0Â°F (12.2Â°C). The wind is blowing at 4.3 mph from the north, and the humidity is at 93%.', \n",
    "    response_metadata={\n",
    "        'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1732, 'total_tokens': 1778}, \n",
    "        'model_name': 'gpt-3.5-turbo', \n",
    "        'system_fingerprint': None, \n",
    "        'finish_reason': 'stop', \n",
    "        'logprobs': None\n",
    "    }, \n",
    "    id='run-de9261f7-2481-4194-b1ac-0e9e5cebaf7b-0', \n",
    "    usage_metadata={'input_tokens': 1732, 'output_tokens': 46, 'total_tokens': 1778}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
