{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Message History (Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RunnableWithMessageHistory` lets us **add message history to certain types of chains**.\n",
    "\n",
    "It:\n",
    "- wraps another Runnable,\n",
    "- manages the chat message history for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, it can be used for any runnable that:\n",
    "-  **takes as input one of**:\n",
    "    - a sequence of `BaseMessage`,\n",
    "    - a `dict` with a key that takes a sequence of `BaseMessage`,\n",
    "    - a `dict` with a key that takes:\n",
    "        - the latest message(s) as a string or sequence of `BaseMessage`, and\n",
    "        - a separate key that takes historical messages.\n",
    "- **and returns as output one of**:\n",
    "    - a string that can be treated as the contents of an `AIMessage`,\n",
    "    - a sequence of `BaseMessage`,\n",
    "    - a `dict` with a key that contains a sequence of `BaseMessage`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some examples to see how it works.\n",
    "\n",
    "First, we construct a runnable which, here:\n",
    "- accepts a `dict` as input,\n",
    "- returns a message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You're an assistant who's good at {ability}. Respond in 20 words or fewer.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **API Reference**:\n",
    "> - [**ChatPromptTemplate**](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "> - [**MessagesPlaceholder**](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html)\n",
    "> - [**ChatOpenAI**](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage the message history, we will need:\n",
    "1. this runnable,\n",
    "2. a callable that returns an instance of `BaseChatMessageHistory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check out the [**memory integrations**](https://integrations.langchain.com/memory) page for implementations of chat message histories using Redis and other providers.\n",
    "\n",
    "Here, we will demonstrate using an **in-memory** `ChatMessageHistory` as well as more persistent storage using `RedisChatMessageHistory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
